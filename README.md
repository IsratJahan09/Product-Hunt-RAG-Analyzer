# ğŸ§  Product Hunt RAG Analyzer

The Product Hunt RAG Analyzer is an AI-powered competitive intelligence system that analyzes Product Hunt competitors using Retrieval-Augmented Generation (RAG).
It transforms raw Product Hunt data into actionable business insights such as feature gaps, sentiment trends, market positioning, and strategic recommendations.

[![Python 3.9+](https://img.shields.io/badge/python-3.9+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Streamlit](https://img.shields.io/badge/Streamlit-1.28+-FF4B4B.svg)](https://streamlit.io/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.100+-009688.svg)](https://fastapi.tiangolo.com/)

## ğŸ“‹ Overview

Product Hunt RAG Analyzer helps entrepreneurs and product managers understand the competitive landscape by analyzing Product Hunt products and their reviews. Simply describe your product idea, and the system will:

- **Identify Competitors**: Find similar products using semantic search with FAISS vector indices
- **Analyze Sentiment**: Understand user sentiment from reviews using transformer-based NLP
- **Extract Feature Gaps**: Discover missing features and opportunities from user feedback
- **Generate Insights**: Create comprehensive competitive intelligence reports using LLM (Groq API)
- **Provide Recommendations**: Get actionable market positioning and differentiation strategies

## âœ¨ Features

| Feature | Description |
|---------|-------------|
| ğŸ” **Semantic Search** | FAISS-powered vector similarity search for competitor identification |
| ğŸ’¬ **Sentiment Analysis** | RoBERTa-based sentiment analysis with aspect extraction |
| ğŸ“Š **Feature Analysis** | Automated feature gap detection and prioritization |
| ğŸ¤– **LLM Generation** | Groq API integration for intelligent insights generation |
| ğŸ“ˆ **Market Positioning** | Competitive landscape analysis and saturation detection |
| ğŸ“„ **Report Generation** | Export reports in JSON, Markdown, or PDF formats |
| ğŸŒ **REST API** | FastAPI backend with OpenAPI documentation |
| ğŸ–¥ï¸ **Web Interface** | Streamlit-based interactive dashboard |
| âš¡ **CLI Tool** | Command-line interface for automation and scripting |

## ğŸ—ï¸ Architecture
1.
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                    
â”‚                        User Interfaces                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Streamlit UI   â”‚     FastAPI REST    â”‚         CLI             â”‚
â”‚  (streamlit_app)â”‚     (src/api)       â”‚      (src/cli.py)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                   â”‚                       â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Analysis Pipeline (src/main.py)              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Stage 1: Competitor Identification                             â”‚
â”‚  Stage 2: Review Retrieval & Analysis                           â”‚
â”‚  Stage 3: LLM Generation                                        â”‚
â”‚  Stage 4: Report Generation                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â–¼                   â–¼                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Embeddings    â”‚ â”‚    Sentiment    â”‚ â”‚    Feature Analysis     â”‚
â”‚  (MiniLM-L6)    â”‚ â”‚   (RoBERTa)     â”‚ â”‚  (Gap Detection)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                   â”‚                       â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    FAISS Vector Storage                         â”‚
â”‚              (Products Index + Reviews Index)                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

```
2.Quick review
```
User Idea
   â†“
Embedding
   â†“
FAISS Retrieval (Competitors)
   â†“
Review Retrieval
   â†“
Sentiment + Feature Analysis
   â†“
LLM (RAG Context)
   â†“
Strategic Insights
   â†“
Structured Report
```

## ğŸš€ Quick Start

### Prerequisites

- Python 3.9 or higher
- [Groq API Key](https://console.groq.com/) (free tier available)

### Installation

1. **Clone the repository**
   ```bash
   git clone https://github.com/yourusername/product-hunt-rag-analyzer.git
   cd product-hunt-rag-analyzer
   ```

2. **Create virtual environment**
   ```bash
   python -m venv .venv
   
   # Windows
   .venv\Scripts\activate
   
   # Linux/macOS
   source .venv/bin/activate
   ```

3. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   ```

4. **Configure environment**
   ```bash
   # Copy example environment file
   cp .env.example .env
   
   # Edit .env and add your Groq API key
   # GROQ_API_KEY=your_api_key_here
   ```

5. **Build FAISS indices** (required before first use)
   ```bash
   python -m src.cli build-index --dataset-path dataset --output-dir data/indices
   ```

### Running the Application

#### Option 1: Web Interface (Streamlit)
```bash
streamlit run streamlit_app/app.py
```
Access at: http://localhost:8501

#### Option 2: REST API (FastAPI)
```bash
python -m src.cli serve --host 0.0.0.0 --port 8000
```
- API: http://localhost:8000
- Docs: http://localhost:8000/docs
- ReDoc: http://localhost:8000/redoc

#### Option 3: Command Line
```bash
python -m src.cli analyze \
    --product-idea "A task management app with AI-powered prioritization" \
    --max-competitors 5 \
    --output-format json \
    --output-file report.json
```

## ğŸ“– Usage

### CLI Commands

| Command | Description |
|---------|-------------|
| `build-index` | Build FAISS indices from Product Hunt dataset |
| `analyze` | Run competitive analysis for a product idea |
| `stats` | Display dataset statistics from indices |
| `serve` | Start FastAPI web service |
| `evaluate` | Run system evaluation and validation |

#### Examples

```bash
# Build indices with IVF index type for large datasets
python -m src.cli build-index \
    --dataset-path dataset \
    --output-dir data/indices \
    --index-type ivf

# Run analysis with custom competitor count
python -m src.cli analyze \
    --product-idea "An AI-powered code review tool for developers" \
    --max-competitors 10 \
    --output-format markdown \
    --output-file analysis_report.md

# View dataset statistics
python -m src.cli stats --indices-dir data/indices

# Run full system evaluation
python -m src.cli evaluate --eval-type full --output-format html
```

### API Endpoints

| Method | Endpoint | Description |
|--------|----------|-------------|
| `GET` | `/health` | Health check |
| `GET` | `/stats` | Dataset statistics |
| `POST` | `/analyze` | Submit analysis request |
| `GET` | `/analysis/{id}` | Get analysis results |

#### Example API Request

```bash
curl -X POST "http://localhost:8000/analyze" \
    -H "Content-Type: application/json" \
    -d '{
        "product_idea": "A collaborative whiteboard for remote teams",
        "max_competitors": 5,
        "output_format": "json"
    }'
```

## ğŸ“ Project Structure

```
product-hunt-rag-analyzer/
â”œâ”€â”€ config/
â”‚   â””â”€â”€ default_config.yaml     # Application configuration
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ indices/                # FAISS vector indices
â”‚   â”œâ”€â”€ processed/              # Processed data files
â”‚   â””â”€â”€ raw/                    # Raw data files
â”œâ”€â”€ dataset/
â”‚   â”œâ”€â”€ products.jsonl          # Product Hunt products
â”‚   â”œâ”€â”€ reviews.jsonl           # Product reviews
â”‚   â””â”€â”€ evaluation/             # Evaluation datasets
â”œâ”€â”€ logs/                       # Application logs
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ api/                    # FastAPI REST API
â”‚   â”‚   â”œâ”€â”€ app.py              # FastAPI application
â”‚   â”‚   â”œâ”€â”€ models.py           # Pydantic models
â”‚   â”‚   â””â”€â”€ routers/            # API route handlers
â”‚   â”œâ”€â”€ evaluation/             # Evaluation framework
â”‚   â”‚   â”œâ”€â”€ metrics.py          # Evaluation metrics
â”‚   â”‚   â”œâ”€â”€ runner.py           # Evaluation runner
â”‚   â”‚   â””â”€â”€ validation.py       # Validation utilities
â”‚   â”œâ”€â”€ modules/                # Core analysis modules
â”‚   â”‚   â”œâ”€â”€ embeddings.py       # Embedding generation
â”‚   â”‚   â”œâ”€â”€ feature_analysis.py # Feature extraction
â”‚   â”‚   â”œâ”€â”€ llm_generation.py   # LLM integration
â”‚   â”‚   â”œâ”€â”€ positioning_analysis.py # Market positioning
â”‚   â”‚   â”œâ”€â”€ preprocessing.py    # Text preprocessing
â”‚   â”‚   â”œâ”€â”€ rag_retrieval.py    # RAG retrieval logic
â”‚   â”‚   â”œâ”€â”€ report_generation.py # Report generation
â”‚   â”‚   â”œâ”€â”€ sentiment.py        # Sentiment analysis
â”‚   â”‚   â””â”€â”€ vector_storage.py   # FAISS index management
â”‚   â”œâ”€â”€ utils/                  # Utility modules
â”‚   â”‚   â”œâ”€â”€ config.py           # Configuration management
â”‚   â”‚   â”œâ”€â”€ dataset_loader.py   # Dataset loading
â”‚   â”‚   â”œâ”€â”€ index_builder.py    # Index building utilities
â”‚   â”‚   â”œâ”€â”€ logger.py           # Logging utilities
â”‚   â”‚   â””â”€â”€ rate_limiter.py     # API rate limiting
â”‚   â”œâ”€â”€ cli.py                  # Command-line interface
â”‚   â””â”€â”€ main.py                 # Main analysis pipeline
â”œâ”€â”€ streamlit_app/              # Streamlit web interface
â”‚   â”œâ”€â”€ app.py                  # Main Streamlit app
â”‚   â”œâ”€â”€ components/             # UI components
â”‚   â”œâ”€â”€ pages/                  # Multi-page app pages
â”‚   â””â”€â”€ utils/                  # Frontend utilities
â”œâ”€â”€ .env.example                # Environment variables template
â”œâ”€â”€ Makefile                    # Build automation
â”œâ”€â”€ requirements.txt            # Python dependencies
â”œâ”€â”€ ProductHunt_RAG_Finetuning.ipynb           
â””â”€â”€ setup.py                    # Package setup
```

## âš™ï¸ Configuration

Configuration is managed via `config/default_config.yaml`. Key settings:

```yaml
# Model Configuration
models:
  embedding:
    name: "all-MiniLM-L6-v2"    # Sentence transformer model
    device: "cpu"                # cpu or cuda
  
  sentiment:
    name: "cardiffnlp/twitter-roberta-base-sentiment-latest"
    
  llm:
    provider: "groq"
    model: "llama-3.3-70b-versatile"
    temperature: 0.7
    max_tokens: 3000

# Retrieval Configuration
retrieval:
  max_competitors: 5
  reviews_per_competitor: 10
  min_similarity_threshold: 0.5

# FAISS Index Configuration
storage:
  faiss:
    index_type: "flat"          # flat, ivf, or hnsw
```

### Environment Variables

| Variable | Description | Default |
|----------|-------------|---------|
| `GROQ_API_KEY` | Groq API key for LLM | Required |
| `FASTAPI_HOST` | API server host | `0.0.0.0` |
| `FASTAPI_PORT` | API server port | `8000` |
| `LOG_LEVEL` | Logging level | `INFO` |
| `INDICES_DIR` | FAISS indices directory | `./data/indices` |

## ğŸ§ª Testing

```bash
# Run all tests with coverage
pytest tests/ -v --cov=src --cov-report=html

# Run specific test module
pytest tests/test_embeddings.py -v

# Run with verbose output
make test
```

## ğŸ“Š Evaluation

The system includes a comprehensive evaluation framework:

```bash
# Full system evaluation
python -m src.cli evaluate --eval-type full --output-format html

# Retrieval quality evaluation
python -m src.cli evaluate --eval-type retrieval

# Sentiment analysis evaluation
python -m src.cli evaluate --eval-type sentiment

# Feature gap detection evaluation
python -m src.cli evaluate --eval-type feature_gaps
```

## ğŸ› ï¸ Development

### Using Makefile

```bash
make help          # Show available commands
make install       # Install dependencies
make setup         # Set up environment
make build-index   # Build FAISS indices
make run-api       # Start FastAPI server
make run-cli       # Run CLI example
make test          # Run tests
make clean         # Clean generated files
make quickstart    # Full setup + build indices
```

### Code Quality

```bash
# Format code
make format

# Lint code
make lint

# Type checking
make type-check
```

## ğŸ”§ Troubleshooting

### Common Issues

**1. FAISS indices not found**
```bash
# Build indices first
python -m src.cli build-index --dataset-path dataset --output-dir data/indices
```

**2. Groq API connection error**
- Verify your API key in `.env`
- Check internet connectivity
- Ensure API key has sufficient quota

**3. Out of memory during embedding generation**
- Reduce batch size in config: `processing.embedding_batch_size: 16`
- Use CPU instead of GPU: `models.embedding.device: "cpu"`

**4. Slow analysis performance**
- Use IVF or HNSW index types for large datasets
- Enable GPU acceleration if available
- Reduce `reviews_per_competitor` in config

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

## ğŸ“¬ Contact

For questions or feedback, please open an issue on GitHub.

---

Built with â¤ï¸ using Python, FastAPI, Streamlit, and Groq
